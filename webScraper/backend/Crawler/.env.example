# Crawler Configuration
# Copy this file to .env and configure your settings

# Database
DATABASE_URL=postgresql://postgres:password@localhost:5432/webscraper

# Redis (optional - for distributed task queue)
# REDIS_URL=redis://localhost:6379/0

# Scraping
SCRAPE_CONCURRENCY=10
DEFAULT_SCRAPE_INTERVAL_MINUTES=60
MAX_SCRAPE_PAGES=10
MAX_RAW_PAYLOAD_BYTES=5000000

# HTTP Client
USER_AGENT_POOL=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36,Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36
PROXY_POOL=
TIMEOUT_SECONDS=30
MAX_RETRIES=3
RETRY_BASE_SECONDS=2

# Rate Limiting
REQUESTS_PER_DOMAIN_PER_MINUTE=30
POLITE_DELAY_SECONDS=2.0

# Logging
LOG_LEVEL=INFO

# Normalization
INGEST_VERSION=1.0.0
